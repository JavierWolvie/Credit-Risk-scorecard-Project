{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e586dec-1504-40a0-acec-86717c236c2b",
   "metadata": {},
   "source": [
    "# Enhancing Creditworthiness Assessment beyond Traditional Credit History.\n",
    "\n",
    "# 1.1 Business Problem\n",
    "Financial institutions face losses due loss of customers as they heavily rely on credit history as the main and sometimes sole factor for determining credit-worthiness of customers. This costs them a lot of credit-worthy customers. In this project I use other factors to prove credit-worthiness of some customers instead of the unfair traditional credit history.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda6c5e9-67a9-4c82-b3d2-2bca87c45365",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1.2 Business understanding\n",
    "Traditional financial institutions have historically relied on formal credit history as the primary basis for loan approval, a practice rooted in the development of centralized credit bureaus and standardized credit scoring systems in mature financial markets. These systems were designed to provide a scalable, objective proxy for borrower risk by assuming that past borrowing behavior reliably predicts future repayment. While effective for customers with established credit records, this approach has proven increasingly limiting as banking expands to emerging markets and underserved populations, where large segments of otherwise financially responsible individuals operate outside formal credit systems and therefore lack sufficient credit footprints.\n",
    "\n",
    "As a result, banks continue to reject approximately 25–35% of loan applications, with research and industry evidence indicating that 30–40% of these rejected applicants are in fact creditworthy when assessed using broader financial and behavioral indicators such as income stability, transaction consistency, and expense management. This over-reliance on credit history leads to an estimated 8–12% loss in potential loan volume, translating to KES 800 million–1.2 billion in unrealized lending opportunity for a mid-sized bank issuing KES 10 billion annually. Addressing this gap through enhanced data-driven credit assessment presents a clear opportunity to improve financial inclusion while capturing profitable, low-risk customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da931187-b13c-4fd1-b5c1-e7f66576743c",
   "metadata": {},
   "source": [
    "# 1.3 Data understanding\n",
    "The dataset used in this project was obtained from Kaggle and is composed of seven relational tables containing detailed historical and behavioral credit information for loan applicants. The data represents real-world financial records typically used by traditional lending institutions to assess creditworthiness. Due to the scale and granularity of the data, the dataset captures both current application information and longitudinal credit behavior across multiple financial products. Here is the link to the dataset on kaggle :(https://www.kaggle.com/c/home-credit-default-risk/data)\n",
    "\n",
    "## Overview of Tables\n",
    "1.\tApplication Train (application_train)\n",
    "This is the primary dataset used for model training and contains demographic, socioeconomic, and financial information for each loan applicant. It includes attributes such as income, employment history, family status, housing conditions, and loan characteristics. Importantly, this table contains the target variable indicating whether a customer defaulted on a loan. Each row represents a unique applicant identified by SK_ID_CURR.\n",
    "2.\tApplication Test (application_test)\n",
    "This table has the same structure as the training dataset but does not contain the target variable. It is used for model evaluation and prediction. It allows the trained model to assess credit risk for new applicants using learned patterns.\n",
    "3.\tBureau (bureau)\n",
    "This table contains historical credit records of applicants obtained from external credit bureaus. Each applicant may have multiple entries representing different loans taken in the past. Features include credit type, loan status (active or closed), credit amount, outstanding debt, and overdue amounts. This table provides insight into long-term credit behavior beyond the current loan application.\n",
    "4.\tBureau Balance (bureau_balance)\n",
    "This table provides monthly snapshots of an applicant’s credit status for each loan reported in the bureau table. It contains information such as days past due and loan status over time. With over one million rows, it enables temporal analysis of repayment behavior and credit stability.\n",
    "5.\tPrevious Application (previous_application)\n",
    "This table records past loan applications made by the applicant, whether approved, refused, or canceled. It includes information about loan amounts, application decisions, and contract terms. This table helps identify application behavior patterns, such as repeated rejections or frequent borrowing.\n",
    "6.\tInstallments Payments (installments_payments)\n",
    "This table captures detailed payment history for installment-based loans. It includes scheduled payment amounts, actual payments made, payment delays, and early repayments. With millions of records, it provides strong indicators of repayment discipline and financial responsibility.\n",
    "7.\tCredit Card Balance (credit_card_balance)\n",
    "This table contains monthly credit card usage data such as balances, limits, minimum payments, and utilization. It reflects short-term financial behavior, spending discipline, and credit dependency.\n",
    "8.\tPOS Cash Balance (POS_CASH_balance)\n",
    "This table tracks point-of-sale and cash loan repayment behavior, including delinquency and contract status. It offers insight into small-loan behavior and short-term liquidity management.\n",
    "\n",
    "### Data Characteristics\n",
    "•\tThe dataset contains hundreds of columns across tables, including numeric, categorical, and temporal variables.\n",
    "•\tSeveral tables contain hundreds of thousands to millions of rows, reflecting one-to-many relationships with applicants.\n",
    "•\tMissing values are present in multiple features, often representing absence of credit history rather than data quality issues.\n",
    "•\tAll tables are linked through unique identifiers such as SK_ID_CURR and SK_ID_BUREAU, enabling relational aggregation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed4a17-87c3-48ee-a9fb-c5d0a7f20123",
   "metadata": {},
   "source": [
    "# 1.4 Data Preparation\n",
    "To transform the raw multi-table credit data into a clean, consistent dataset ready for analysis, the first step will be to aggregate and merge all relational tables into a single customer-level dataset using the unique applicant identifier (SK_ID_CURR). Since most auxiliary tables contain one-to-many relationships, relevant numeric and categorical features will be summarized using statistical aggregations such as mean, sum, minimum, maximum, counts, and unique counts. This ensures that each applicant is represented by a single, comprehensive record while preserving historical credit behavior across bureau records, installments, credit cards, POS cash, and previous applications.\n",
    "\n",
    "\n",
    "After merging, data cleaning and consistency checks will be applied. Missing values will be handled using context-appropriate strategies: numerical features will be imputed using median values to reduce the influence of outliers, count-based features will be filled with zeros where missing values indicate absence of credit activity, and categorical variables will be filled using forward fill, backward fill, or meaningful default categories where applicable. Data types will be validated and corrected to ensure numerical features are stored as integers or floats, and binary indicators are properly encoded as integers (0/1). Duplicate records will be checked and removed where necessary to maintain data integrity.\n",
    "\n",
    "\n",
    "Finally, the dataset will be prepared for modeling by engineering ratio features, flags, and normalized metrics that better capture financial behavior, such as debt ratios, utilization rates, and repayment consistency. Outliers will be assessed using statistical methods (e.g., IQR), and feature distributions will be reviewed to ensure stability and low noise. The result will be a single, clean, and analysis-ready dataset that accurately reflects applicant behavior beyond traditional credit history, supporting fairer and more inclusive credit-worthiness assessment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f4db0a-b585-454d-b286-7a084c681a91",
   "metadata": {},
   "source": [
    "# 1.2 Business Objectives\n",
    "# Main objective\n",
    "To use alternative data signals to improve credit approval decisions by accurately identifying creditworthy applicants with limited or no traditional credit history.\n",
    "# Specific objectives\n",
    "i)\tTo identify important features that are neglected by legacy banks.\n",
    "\n",
    "ii)\tTo handle missing values by applying appropriate statistical and logical imputation methods for numerical and categorical features.\n",
    "\n",
    "iii)\tTo engineer alternative creditworthiness features such as repayment behavior, application velocity, and utilization ratios.\n",
    "\n",
    "iv)\tTo encode categorical columns to make them model ready.\n",
    "\n",
    "v)\tTo identify and handle outliers accordingly so that they do not affect the model.\n",
    "\n",
    "vi)\tStandardizing large numbers through log transformation so that they do not overshadow the smaller numbers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdf8092-f033-4b0f-a718-82843bba6812",
   "metadata": {},
   "source": [
    "# Criteria of Success\n",
    "1.\tTo reduce the rejection of creditworthy applicants by at least 30–40% among customers with thin or non-existent credit histories compared to a traditional credit-history-only baseline.\n",
    "2.\tTo lower False Negatives (good borrowers incorrectly declined) by a minimum of 50%, while keeping default risk within acceptable thresholds.\n",
    "3.\tTo demonstrate that ignored features (cash-flow stability, rent payment regularity, skill-based stability income, and first time employees) contribute significantly to credit decisions through measurable feature importance. \n",
    "4.\tTo increase approved loan volume by 8–12% without a corresponding increase in default rates, reflecting recovered missed lending opportunities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827bb219-f542-4773-8b97-3a96a417bc34",
   "metadata": {},
   "source": [
    "# Data validation\n",
    "Data validation is important in this project because it ensures that the data you are working with is accurate, consistent, and trustworthy. Decisions, models, and insights are only as good as the data behind them—if the data is wrong, the conclusions will be wrong too.\n",
    "\n",
    "## Here are the key reasons explained clearly:\n",
    "\n",
    "1. Prevents wrong decisions\n",
    "\n",
    "Invalid data (wrong values, duplicates, incorrect formats) can lead to false insights. For example, a negative income value or an impossible age can distort averages, ratios, and model predictions, leading to poor business decisions.\n",
    "\n",
    "2. Improves model performance\n",
    "\n",
    "In projects like credit risk scoring, invalid or inconsistent data increases noise. This causes models to learn incorrect patterns, increasing false positives or false negatives. Validated data leads to more reliable and stable models.\n",
    "\n",
    "3. Ensures consistency across datasets\n",
    "\n",
    "When working with multiple tables (like application, bureau, installments, POS cash), validation ensures:\n",
    "\n",
    "Keys match correctly (e.g., SK_ID_CURR)\n",
    "\n",
    "Units and formats are consistent\n",
    "\n",
    "Aggregations represent reality\n",
    "Without validation, merges can silently fail or introduce bias.\n",
    "\n",
    "4. Reduces bias and data leakage\n",
    "\n",
    "Data validation helps detect:\n",
    "\n",
    "Duplicates that overweight some customers\n",
    "\n",
    "Future information leaking into training data\n",
    "\n",
    "Outliers that unfairly influence predictions\n",
    "This is critical in regulated domains like finance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3e053b-f65d-4bea-977a-943d4bfa5824",
   "metadata": {},
   "source": [
    " # importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a6e2ed6a-cb8b-485e-8fe2-a98dac218a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "79353468-fda9-479f-a313-a7dd22348c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "#loading the dataset\n",
    "\n",
    "# Main application data\n",
    "app_train = pd.read_csv(r\"C:/Users/USER/Desktop/first project/application_train.csv\")\n",
    "app_test = pd.read_csv(r\"C:/Users/USER/Desktop/first project/application_test.csv\")\n",
    "\n",
    "# Other relational tables\n",
    "bureau = pd.read_csv(r\"C:/Users/USER/Desktop/first project/bureau.csv\")\n",
    "bureau_balance = pd.read_csv(r\"C:/Users/USER/Desktop/first project/bureau_balance.csv\")\n",
    "prev_app = pd.read_csv(r\"C:/Users/USER/Desktop/first project/previous_application.csv\")\n",
    "pos_cash = pd.read_csv(r\"C:/Users/USER/Desktop/first project/POS_CASH_balance.csv\")\n",
    "installments = pd.read_csv(r\"C:/Users/USER/Desktop/first project/installments_payments.csv\")\n",
    "credit_card = pd.read_csv(r\"C:/Users/USER/Desktop/first project/credit_card_balance.csv\")\n",
    "print(\"loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d78ba3a-0af9-4f48-999d-48c034a777df",
   "metadata": {},
   "source": [
    "## Viewing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c2a3cce3-2e72-49be-b241-4068d063f0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 122)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the datasets\n",
    "app_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eb47d3f7-7570-4205-a90e-9277f0a65eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1716428, 17)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ce0f9e71-26f2-496b-9c84-ef5a3be47a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3840312, 23)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_card.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3eb5d631-78eb-4f5d-9b5c-37361e8bd14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13605401, 8)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "94c0ad14-0137-4c4a-8f44-14ebc28a8764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_PREV</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NUM_INSTALMENT_VERSION</th>\n",
       "      <th>NUM_INSTALMENT_NUMBER</th>\n",
       "      <th>DAYS_INSTALMENT</th>\n",
       "      <th>DAYS_ENTRY_PAYMENT</th>\n",
       "      <th>AMT_INSTALMENT</th>\n",
       "      <th>AMT_PAYMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1054186</td>\n",
       "      <td>161674</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-1180.0</td>\n",
       "      <td>-1187.0</td>\n",
       "      <td>6948.360</td>\n",
       "      <td>6948.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1330831</td>\n",
       "      <td>151639</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "      <td>-2156.0</td>\n",
       "      <td>-2156.0</td>\n",
       "      <td>1716.525</td>\n",
       "      <td>1716.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2085231</td>\n",
       "      <td>193053</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>25425.000</td>\n",
       "      <td>25425.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2452527</td>\n",
       "      <td>199697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-2418.0</td>\n",
       "      <td>-2426.0</td>\n",
       "      <td>24350.130</td>\n",
       "      <td>24350.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2714724</td>\n",
       "      <td>167756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1383.0</td>\n",
       "      <td>-1366.0</td>\n",
       "      <td>2165.040</td>\n",
       "      <td>2160.585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_PREV  SK_ID_CURR  NUM_INSTALMENT_VERSION  NUM_INSTALMENT_NUMBER  \\\n",
       "0     1054186      161674                     1.0                      6   \n",
       "1     1330831      151639                     0.0                     34   \n",
       "2     2085231      193053                     2.0                      1   \n",
       "3     2452527      199697                     1.0                      3   \n",
       "4     2714724      167756                     1.0                      2   \n",
       "\n",
       "   DAYS_INSTALMENT  DAYS_ENTRY_PAYMENT  AMT_INSTALMENT  AMT_PAYMENT  \n",
       "0          -1180.0             -1187.0        6948.360     6948.360  \n",
       "1          -2156.0             -2156.0        1716.525     1716.525  \n",
       "2            -63.0               -63.0       25425.000    25425.000  \n",
       "3          -2418.0             -2426.0       24350.130    24350.130  \n",
       "4          -1383.0             -1366.0        2165.040     2160.585  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2f0d9482-284b-4615-ad1d-952c24f30784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27299925, 3)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_balance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "79026e3d-f26b-422a-8a6b-5e8acf566f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48744, 121)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "88a4be0e-626d-45d1-ae84-cdb2cbae9693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001358, 8)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_cash.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437b51eb-583e-40d2-a387-e08323caf671",
   "metadata": {},
   "source": [
    "# merging one to many relationship table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "543fda6b-0ca8-456b-8e79-914af6943bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining aggregation function\n",
    "def aggregate_one_to_many(df, group_key, prefix):\n",
    "    num_cols = df.select_dtypes(include='number').columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "    # Remove group key if present\n",
    "    if group_key in num_cols:\n",
    "        num_cols.remove(group_key)\n",
    "    if group_key in cat_cols:\n",
    "        cat_cols.remove(group_key)\n",
    "\n",
    "    agg_dict = {}\n",
    "\n",
    "    for col in num_cols:\n",
    "        agg_dict[col] = ['mean', 'sum', 'max', 'min']\n",
    "\n",
    "    for col in cat_cols:\n",
    "        agg_dict[col] = ['nunique']\n",
    "\n",
    "    agg = df.groupby(group_key).agg(agg_dict)\n",
    "\n",
    "    agg.columns = [f\"{prefix}_{col}_{stat}\" for col, stat in agg.columns]\n",
    "    agg.reset_index(inplace=True)\n",
    "\n",
    "    return agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6975be-b392-4218-914f-f68edcb01374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregating one to many tables\n",
    "bureau_agg = aggregate_one_to_many(bureau, 'SK_ID_CURR', 'BUREAU')\n",
    "\n",
    "bureau_balance_agg = aggregate_one_to_many(\n",
    "    bureau_balance.merge(bureau[['SK_ID_BUREAU', 'SK_ID_CURR']], \n",
    "                          on='SK_ID_BUREAU', how='left'),\n",
    "    'SK_ID_CURR',\n",
    "    'BB'\n",
    ")\n",
    "\n",
    "prev_app_agg = aggregate_one_to_many(prev_app, 'SK_ID_CURR', 'PREV')\n",
    "\n",
    "installments_agg = aggregate_one_to_many(installments, 'SK_ID_CURR', 'INST')\n",
    "\n",
    "credit_card_agg = aggregate_one_to_many(credit_card, 'SK_ID_CURR', 'CC')\n",
    "\n",
    "pos_cash_agg = aggregate_one_to_many(pos_cash, 'SK_ID_CURR', 'POS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4493b679-e210-4cfc-9d9b-9bd56e7278a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the tables\n",
    "final_df = app_train.copy()\n",
    "\n",
    "final_df = (\n",
    "    final_df\n",
    "    .merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
    "    .merge(bureau_balance_agg, on='SK_ID_CURR', how='left')\n",
    "    .merge(prev_app_agg, on='SK_ID_CURR', how='left')\n",
    "    .merge(installments_agg, on='SK_ID_CURR', how='left')\n",
    "    .merge(credit_card_agg, on='SK_ID_CURR', how='left')\n",
    "    .merge(pos_cash_agg, on='SK_ID_CURR', how='left')\n",
    ")\n",
    "\n",
    "print(final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba16391d-dd53-49f5-baeb-9ec7c754cda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b63ebd-1483-44f2-b552-95ff6c17ec60",
   "metadata": {},
   "source": [
    "# data validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fcba68-a346-4086-86af-da3812594678",
   "metadata": {},
   "source": [
    "### 1.completeness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb47b4-38e1-4157-8448-0bfabbd76308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# completeness check\n",
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf31aa2f-56ee-487e-b2f0-0b402618ed13",
   "metadata": {},
   "source": [
    "###  2. uniqueness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ca87ba-9f7c-46be-99de-4c2f96154835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniqueness check\n",
    "final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e24df5b-74a6-4c83-a01f-dc26fedeb63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336580a1-46ea-44ef-adb4-bd934fa67399",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['DAYS_BIRTH', 'DAYS_EMPLOYED']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab105d2-c126-4175-a9a5-68250d07303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(final_df['DAYS_BIRTH'] > 0).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2ceafb-4a24-4624-988e-3ac6b0f6d439",
   "metadata": {},
   "source": [
    "### 3. Accuracy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb38b39-5eed-4423-bfab-0eab0e529627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify impossible values\n",
    "# Age check (DAYS_BIRTH is negative in Home Credit)\n",
    "final_df['AGE_YEARS'] = (-final_df['DAYS_BIRTH'] / 365).round(1)\n",
    "\n",
    "# Find unrealistic ages\n",
    "invalid_age = final_df[\n",
    "    (final_df['AGE_YEARS'] < 18) | (final_df['AGE_YEARS'] > 100)\n",
    "]\n",
    "\n",
    "print(f\"Invalid age records: {invalid_age.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985946cd-5fb7-4cd8-8682-66caf1aaecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative income\n",
    "invalid_income = final_df[final_df['AMT_INCOME_TOTAL'] < 0]\n",
    "\n",
    "# Zero or negative loan amounts\n",
    "invalid_loan = final_df[final_df['AMT_CREDIT'] <= 0]\n",
    "\n",
    "print(len(invalid_income), len(invalid_loan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d49546-6cfa-4d21-8745-62fa11c2e241",
   "metadata": {},
   "source": [
    "### 4.validity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0465d335-d4e1-4bc8-b4ba-c851535f47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validity check\n",
    "\n",
    "final_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7ba499-2da3-4ee9-86e7-6d1dd286d5a5",
   "metadata": {},
   "source": [
    "### 5. Consistency check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6aed5-5d3f-474c-a435-eaf07e656226",
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent_income = final_df[\n",
    "    (final_df['NAME_INCOME_TYPE'] == 'Unemployed') &\n",
    "    (final_df['AMT_INCOME_TOTAL'] > 0)\n",
    "]\n",
    "\n",
    "print(inconsistent_income.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62370e4-d3b3-45d3-b0fe-d6010c4ca826",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['EMPLOYMENT_YEARS'] = (-final_df['DAYS_EMPLOYED'] / 365)\n",
    "\n",
    "employment_inconsistency = final_df[\n",
    "    final_df['EMPLOYMENT_YEARS'] > final_df['AGE_YEARS']\n",
    "]\n",
    "\n",
    "print(employment_inconsistency.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c00a97-e7c6-4041-bdfe-7d9119c9b5fe",
   "metadata": {},
   "source": [
    "## Data Validation Report\n",
    "\n",
    "After merging and aggregating all source tables into a single dataset (final_df), data validation was performed to ensure the data is accurate, consistent, and ready for analysis and modeling.\n",
    "\n",
    "Completeness:\n",
    "Missing values mainly resulted from left joins where applicants had no historical records. Numerical fields will be filled using median or zero (where absence implies no activity), while categorical fields will be handled using appropriate method of analysis e.g. mode or “Unknown”. Columns with excessive missing values were flagged for feature selection.\n",
    "\n",
    "Accuracy:\n",
    "Checks were conducted to identify unrealistic values such as negative incomes, invalid credit amounts, and extreme ratios. I found the data to be legit and accurate therefore ready for usage.\n",
    "\n",
    "Consistency:\n",
    "A consistency check was performed between income type and reported income. Applicants labeled as “Unemployed” but reporting positive income were flagged as logically inconsistent. These cases were reviewed to identify potential data quality issues or alternative income sources not captured by traditional employment labels.\n",
    "Logical relationships across features were validated, such as alignment between credit amounts, installments, and repayment behavior. 22 inconsistensies found in two columns and will be handled by flagging them down hence creating great features for the model.\n",
    "\n",
    "Uniqueness:\n",
    "Duplicate records were checked using SK_ID_CURR to ensure one row per applicant. No duplicate customer records were found out.\n",
    "\n",
    "Conclusion:\n",
    "The dataset passed all major validation checks and is considered clean, consistent, and reliable for feature engineering and predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89e6095-2f63-4f7d-bfe5-6220d1fbeb67",
   "metadata": {},
   "source": [
    "# Data Remediation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0443dfa-a36a-4af3-9c13-06dc99159eb8",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a368fb3c-d0fa-4b4d-a897-e0b399848082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling the inconsistensy by flagging it down\n",
    "final_df['INCOME_TYPE_MISMATCH'] = (\n",
    "    (final_df['NAME_INCOME_TYPE'] == 'Unemployed') &\n",
    "    (final_df['AMT_INCOME_TOTAL'] > 0)\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17adae42-562f-4f62-83ac-71172d98d06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get numeric columns\n",
    "numeric_cols = final_df.select_dtypes(include='number').columns\n",
    "\n",
    "# Filter only columns with null values\n",
    "cols_with_null = final_df[numeric_cols].isnull().sum()\n",
    "cols_with_null = cols_with_null[cols_with_null > 0].index\n",
    "\n",
    "# Compute medians for those columns\n",
    "medians = final_df[cols_with_null].median()\n",
    "print(\"Medians for columns with null values:\\n\", medians)\n",
    "#because mean is not affected by outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b81c000-6f3f-4630-8285-3f49be4f2833",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_fill_zero = [\n",
    "    'POS_SK_DPD_DEF_mean',\n",
    "    'POS_SK_DPD_DEF_sum',\n",
    "    'POS_SK_DPD_DEF_max',\n",
    "    'POS_SK_DPD_DEF_min'\n",
    "]\n",
    "\n",
    "final_df[cols_to_fill_zero] = final_df[cols_to_fill_zero].fillna(0)\n",
    "# because they show no hsitory in that column. was never present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e961e6-6d6a-4f6c-891b-c39d7171e902",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[cols_to_fill_zero].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc5f53-c0e6-4c21-b21b-6fbaeecc5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['POS_NAME_CONTRACT_STATUS_nunique'] = (\n",
    "    final_df['POS_NAME_CONTRACT_STATUS_nunique'].fillna(0)\n",
    ")\n",
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6d9b0-e993-41d6-be89-53877dcc7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling the 22 inconsistensies\n",
    "\n",
    "final_df.loc[\n",
    "    (final_df['NAME_INCOME_TYPE'] == 'Unemployed') &\n",
    "    (final_df['AMT_INCOME_TOTAL'] > 0),\n",
    "    'NAME_INCOME_TYPE'\n",
    "] = 'Other'\n",
    "\n",
    "# i prefer this method because it \n",
    "#Keeps customer\n",
    "# Realistic to African informal economies\n",
    "# preserves income signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf97cdc-1e35-421b-984c-ae20b92e6761",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c27d4-13ca-43aa-a2c8-a45304500bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3823744d-4b42-415a-ae72-22cf99c4320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373de9f1-0d25-498d-af32-486d4f829bf9",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83531c-4d7f-4344-a575-ef0f437a318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2068ade-27b4-4e45-8708-c0fb731edc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make sure final_df is a copy\n",
    "\n",
    "final_df = final_df.copy()\n",
    "\n",
    "\n",
    "# 1. Feature Engineering\n",
    "\n",
    "# 1. Income & Credit Capacity\n",
    "final_df['CREDIT_INCOME_RATIO'] = final_df['AMT_CREDIT'] / final_df['AMT_INCOME_TOTAL']\n",
    "final_df['ANNUITY_INCOME_RATIO'] = final_df['AMT_ANNUITY'] / final_df['AMT_INCOME_TOTAL']\n",
    "final_df['GOODS_PRICE_CREDIT_RATIO'] = final_df['AMT_GOODS_PRICE'] / final_df['AMT_CREDIT']\n",
    "\n",
    "# 2. Employment & Age Stability\n",
    "final_df['EMPLOYED_YEARS'] = np.abs(final_df['DAYS_EMPLOYED']) / 365\n",
    "final_df['AGE_YEARS'] = np.abs(final_df['DAYS_BIRTH']) / 365\n",
    "final_df['EMPLOYMENT_AGE_RATIO'] = final_df['EMPLOYED_YEARS'] / final_df['AGE_YEARS']\n",
    "\n",
    "# 3. External Source Aggregations\n",
    "ext_sources = ['EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']\n",
    "final_df['EXT_SOURCE_MEAN'] = final_df[ext_sources].mean(axis=1)\n",
    "final_df['EXT_SOURCE_MAX'] = final_df[ext_sources].max(axis=1)\n",
    "final_df['EXT_SOURCE_MIN'] = final_df[ext_sources].min(axis=1)\n",
    "\n",
    "# 4. Credit History Presence Flags\n",
    "final_df['HAS_BUREAU_HISTORY'] = (final_df['BUREAU_SK_ID_BUREAU_sum'] > 0).astype(int)\n",
    "final_df['HAS_PREV_APPLICATION'] = (final_df['PREV_SK_ID_PREV_sum'] > 0).astype(int)\n",
    "final_df['HAS_POS_HISTORY'] = (final_df['POS_SK_ID_PREV_sum'] > 0).astype(int)\n",
    "final_df['HAS_CC_HISTORY'] = (final_df['CC_SK_ID_PREV_sum'] > 0).astype(int)\n",
    "\n",
    "# 5. Delinquency / Risk Features\n",
    "final_df['TOTAL_DPD'] = (\n",
    "    final_df['BUREAU_CREDIT_DAY_OVERDUE_sum'] +\n",
    "    final_df['POS_SK_DPD_sum'] +\n",
    "    final_df['CC_SK_DPD_sum']\n",
    ")\n",
    "final_df['TOTAL_DPD_DEF'] = final_df['POS_SK_DPD_DEF_sum'] + final_df['CC_SK_DPD_DEF_sum']\n",
    "\n",
    "# 6. Credit Card Utilization\n",
    "final_df['CC_UTILIZATION'] = final_df['CC_AMT_BALANCE_mean'] / final_df['CC_AMT_CREDIT_LIMIT_ACTUAL_mean']\n",
    "\n",
    "# 7. Installment Payment Behavior\n",
    "final_df['INST_PAYMENT_RATIO'] = final_df['INST_AMT_PAYMENT_mean'] / final_df['INST_AMT_INSTALMENT_mean']\n",
    "\n",
    "# 8. Loan Activity Intensity\n",
    "final_df['TOTAL_LOAN_COUNT'] = (\n",
    "    final_df['BUREAU_SK_ID_BUREAU_sum'] +\n",
    "    final_df['PREV_SK_ID_PREV_sum'] +\n",
    "    final_df['POS_SK_ID_PREV_sum'] +\n",
    "    final_df['CC_SK_ID_PREV_sum']\n",
    ")\n",
    "\n",
    "# 9. Recent Application Behavior\n",
    "final_df['RECENT_APPLICATION'] = (final_df['PREV_DAYS_DECISION_min'] > -30).astype(int)\n",
    "\n",
    "# 10. Housing / Living Quality\n",
    "final_df['LIVING_AREA_RATIO'] = final_df['LIVINGAREA_AVG'] / final_df['TOTALAREA_MODE']\n",
    "\n",
    "\n",
    "# 2. Handle Missing / Infinite Values\n",
    "\n",
    "# Replace inf/-inf with NaN\n",
    "final_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaN for sum/count features\n",
    "fill_zero_cols = ['TOTAL_DPD','TOTAL_DPD_DEF','CC_UTILIZATION','TOTAL_LOAN_COUNT']\n",
    "final_df[fill_zero_cols] = final_df[fill_zero_cols].fillna(0)\n",
    "\n",
    "# Binary features (ensure integer)\n",
    "binary_cols = ['HAS_BUREAU_HISTORY','HAS_PREV_APPLICATION','HAS_POS_HISTORY','HAS_CC_HISTORY','RECENT_APPLICATION']\n",
    "final_df[binary_cols] = final_df[binary_cols].fillna(0).astype(int)\n",
    "\n",
    "# Ratio / numeric features\n",
    "ratio_cols = [\n",
    "    'CREDIT_INCOME_RATIO','ANNUITY_INCOME_RATIO','GOODS_PRICE_CREDIT_RATIO',\n",
    "    'EMPLOYED_YEARS','AGE_YEARS','EMPLOYMENT_AGE_RATIO',\n",
    "    'EXT_SOURCE_MEAN','EXT_SOURCE_MAX','EXT_SOURCE_MIN',\n",
    "    'CC_UTILIZATION','INST_PAYMENT_RATIO','LIVING_AREA_RATIO'\n",
    "]\n",
    "final_df[ratio_cols] = final_df[ratio_cols].fillna(0)\n",
    "\n",
    "\n",
    "# 3. Scale Ratio Features\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "final_df[ratio_cols] = scaler.fit_transform(final_df[ratio_cols])\n",
    "\n",
    "\n",
    "# 4. Preview Engineered Features\n",
    "engineered_features = binary_cols + ratio_cols + fill_zero_cols\n",
    "print(\"✅ Engineered, cleaned, and scaled features preview:\")\n",
    "print(final_df[engineered_features].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722cea86-8eae-4ced-a8af-275ef06019c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49e627-41fa-4c06-9a55-9e98a99923ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f15f71-d94f-425a-97e7-1c160c576936",
   "metadata": {},
   "source": [
    "  # Exploratory Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f2cc5-22ad-46d7-9e32-6d8d0a1c65c1",
   "metadata": {},
   "outputs": [],
   "source": [
    " final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f05cde-0bb6-41ef-982e-e14302fc9df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374eb7ac-7a01-4f57-865c-b851ab3c1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cc9479-b06b-495a-92c3-5db05200da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18c990-9c82-4e1f-8487-f10d8551d988",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d980b2f-bec7-40ec-863f-0dde8514f2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf76bd08-8be9-4ba2-a3ee-11dfcd3fc626",
   "metadata": {},
   "source": [
    "# Univariate EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913cb53c-dd62-45d5-830e-8af79009b917",
   "metadata": {},
   "source": [
    "## Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b34f03-1da5-4bed-879b-ea8e0895f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['AMT_INCOME_TOTAL'].hist(bins=5)\n",
    "\n",
    "plt.title('Distribution of Total income')\n",
    "plt.xlabel('No. of applicants')\n",
    "plt.ylabel('Total income')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ca4280-e36d-4efd-b9a0-4ddde6a9e3ae",
   "metadata": {},
   "source": [
    "## comment\n",
    "the visual shows that the vast majority of the applicants are in the lowest bracket, while a few applicants have higher incomes \n",
    "\n",
    "## Recommendation\n",
    "use log scale for highly skewed data\n",
    "check for outliers and verify that the high points are legitimate data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb2172-273b-45e5-8eb6-b80f98afddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "final_df['AMT_CREDIT'].hist(bins=25)\n",
    "\n",
    "plt.title('Distribution of Credit Amount')\n",
    "plt.xlabel('No. of applicants')\n",
    "plt.ylabel('credit amount')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca9e805-23cc-4968-b7da-9786c76f92a9",
   "metadata": {},
   "source": [
    "## comment\n",
    "the data has a positive skewness and a few outliers.\n",
    "\n",
    "## Recommendation\n",
    "Use median to handle missing values in such dataset as it cannot be corrupted by outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de26fc5d-be2f-48f6-bc79-438e55f9bccb",
   "metadata": {},
   "source": [
    "## Checking for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2c1b3f-4199-4bb0-a271-1b42a2c27218",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.boxplot(column = 'AMT_CREDIT')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffd2043-9428-43b7-9350-c2abde59cba4",
   "metadata": {},
   "source": [
    "## comment\n",
    "the data is right skewed and there is outliers in plenty\n",
    "\n",
    "## Recommendation\n",
    "Donot remove outliers and null values blindly rather use robust statistical methods e.g. median to fill null values in a data that has outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d997b0-2f2b-4eb1-bf6a-891a8b9b2d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.boxplot(column = 'AMT_INCOME_TOTAL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf950131-1438-48d7-addf-8fc352a1bc06",
   "metadata": {},
   "source": [
    "## comment\n",
    "there is high positive skewness and a good number of outliers.\n",
    "\n",
    "## recommendation\n",
    "you should handle outliers effectively to avoid skewing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b607e7-746a-4396-8282-673824e367e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.boxplot(column ='AMT_ANNUITY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e96b34e-1a0a-4075-aa0d-d5590cba3264",
   "metadata": {},
   "source": [
    "## comment\n",
    "The data is heavily right skewed and there is extreme outliers\n",
    "\n",
    "## recommendation\n",
    "handle the outliers with the right statistical method of filling missing values e.g. median whch cannot be affected by outliers. you can also use log to deal with outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162dd746-f368-4582-b46e-5c0b3b818579",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.boxplot(column ='AGE_YEARS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfbd408-9cda-4878-87ac-23aad004ac6c",
   "metadata": {},
   "source": [
    "## comment\n",
    "the data is evenly skewed and symmetrical.\n",
    "\n",
    "## recommendation\n",
    "there is no log transformation needed here for an obvious reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e2084-7a4b-4106-8c47-ec2756073331",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.boxplot(column ='EMPLOYMENT_YEARS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15720316-e59a-4242-ad38-291b960cec99",
   "metadata": {},
   "source": [
    "## comment\n",
    "there is negative skewness and a mix of positive and negative ages of employment.\n",
    "\n",
    "## recommendation\n",
    "handle the signs in the ages as all should be negative "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009c593-ba0f-4d40-b397-c62d3b0f5f3c",
   "metadata": {},
   "source": [
    "## checking skewness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25d1e48-0f75-485f-982f-0bf8f1b6ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['EMPLOYMENT_YEARS'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d31ce-c616-4766-89fa-277a1474560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['AGE_YEARS'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2174da-cab8-47a0-84ea-aacf7de2e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['AMT_ANNUITY'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906b36fd-9382-486b-a813-16a5fa19ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['AMT_INCOME_TOTAL'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60150482-4277-40f0-94a2-62217d8d51be",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['AMT_CREDIT'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c347c5e-8374-4819-b4ae-0a595cc2b812",
   "metadata": {},
   "source": [
    "# Bivariate EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a962bf3e-4bd9-4031-b4de-ed5026f3ecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUMERICAL VS NUMERICAL ANALYSIS\n",
    "final_df[['AMT_INCOME_TOTAL', 'AMT_ANNUITY']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b5c44c-6b2c-482b-8366-207294a591d0",
   "metadata": {},
   "source": [
    "## comment\n",
    "there is a weak positive relationship between the two columns.AS one increases the other tend to increase slightly.\n",
    "## recommendation\n",
    " Donot assume that the two columns directly affect each other.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d177f02-500c-4558-90c8-1a89ccd3cd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(final_df['AMT_INCOME_TOTAL'], final_df['AMT_ANNUITY'])\n",
    "plt.xlabel('AMT_INCOME_TOTAL')\n",
    "plt.ylabel('AMT_ANNUITY')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf11d43-75bd-4883-8c49-0e0c6e55231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['AMT_INCOME_TOTAL', 'AMT_CREDIT']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee0aa05-93df-485e-8327-62acdf0b002a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['AMT_INCOME_TOTAL', 'EMPLOYMENT_YEARS']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6347493-ec45-4712-84af-c3306da59c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[['AMT_INCOME_TOTAL', 'AGE_YEARS']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d5befb-e7a2-4f91-9e07-24cd11a5b6b2",
   "metadata": {},
   "source": [
    "## comment \n",
    "there is a weak negative relationship between age and total income.\n",
    "## recommendation\n",
    "Bigger age doesnot mean higher income."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a39eb-5e4c-445b-b0aa-f61d40f408d9",
   "metadata": {},
   "source": [
    "# Multivariate EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdffc33a-2ab0-45a9-bd41-c096244182de",
   "metadata": {},
   "outputs": [],
   "source": [
    "VYU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
